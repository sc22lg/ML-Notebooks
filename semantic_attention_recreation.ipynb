{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiqwndBPop8rj+lK5Tvwou",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sc22lg/ML-Notebooks/blob/gpt2-small-paper-recreation/semantic_attention_recreation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Recreation of the Results of: The Self-Hating Attention Head: A Deep Dive in GPT-2 - Matteo Migliarini July 2025\n",
        "by Leo Gott\n",
        "\n",
        "Original publication can be found [here](https://www.lesswrong.com/posts/wxPvdBwWeaneAsWRB/the-self-hating-attention-head-a-deep-dive-in-gpt-2-1)"
      ],
      "metadata": {
        "id": "GvOoVJ01k5Ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall idea:\n",
        "\"gpt2-small's head L1H5 directs attention to semantically similar tokens and actively suppresses self-attention\"\n",
        "### Results to re-create:\n",
        "- Create inputs to ellicit expected behaviour\n",
        "- Use inputs to identify heads performing behaviour in gpt2-small (expected head L1H5)\n",
        "- Perform mean-ablation of preceding components to find which components effect L1H5"
      ],
      "metadata": {
        "id": "BkQK5fgbl0_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup:"
      ],
      "metadata": {
        "id": "tDwZTA1Tr4F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import pkg_resources\n",
        "\n",
        "installed_packages = [pkg.key for pkg in pkg_resources.working_set]\n",
        "if \"transformer-lens\" not in installed_packages:\n",
        "    %pip install transformer_lens==2.11.0 einops eindex-callum jaxtyping git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
        "\n",
        "import pandas as pd\n",
        "import circuitsvis as cv\n",
        "import einops\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformer_lens import (\n",
        "    ActivationCache,\n",
        "    FactoredMatrix,\n",
        "    HookedTransformer,\n",
        "    HookedTransformerConfig,\n",
        "    utils,\n",
        ")\n",
        "from transformer_lens.hook_points import HookPoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUuoGz1ur6Ct",
        "outputId": "7bb810da-c2a2-446d-dfb6-b90f442f362b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3825944965.py:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  import pkg_resources\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Generate input prompt"
      ],
      "metadata": {
        "id": "a63A0WEToMzV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNsmbpepkrtX",
        "outputId": "e43647e8-eff3-4e14-ecb5-1e42eb3dcd2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0         1           2          3           4           5\n",
            "0  Monday   Tuesday   Wednesday   Thursday      Friday    Saturday\n",
            "1     red      blue       green     silver       white        Blue\n",
            "2    1918      1920        1930       1943        1998        2000\n",
            "3     You        He         his        she         her       their\n",
            "4   Italy   Iceland     Austria     Mexico       Spain      France\n",
            "5     dog       cat       horse    hamster        fish      lizard\n",
            "6      60        65          69         70          71          90\n",
            "7   angry     happy         sad    excited       bored    stressed\n",
            "8     car       bus         van      truck   motorbike   aeroplane\n"
          ]
        }
      ],
      "source": [
        "semantic_words_file = pd.read_csv('semantic_words.csv', header=None)\n",
        "print(semantic_words_file.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kPTOFv_Hu2IW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}