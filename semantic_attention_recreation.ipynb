{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYcWBjeehaH29PPHxA1b3T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sc22lg/ML-Notebooks/blob/gpt2-small-paper-recreation/semantic_attention_recreation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Recreation of the Results of: The Self-Hating Attention Head: A Deep Dive in GPT-2 - Matteo Migliarini July 2025\n",
        "by Leo Gott\n",
        "\n",
        "Original publication can be found [here](https://www.lesswrong.com/posts/wxPvdBwWeaneAsWRB/the-self-hating-attention-head-a-deep-dive-in-gpt-2-1)"
      ],
      "metadata": {
        "id": "GvOoVJ01k5Ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall idea:\n",
        "\"gpt2-small's head L1H5 directs attention to semantically similar tokens and actively suppresses self-attention\"\n",
        "### Results to re-create:\n",
        "- Create inputs to ellicit expected behaviour\n",
        "- Use inputs to identify heads performing behaviour in gpt2-small (expected head L1H5)\n",
        "- Perform mean-ablation of preceding components to find which components effect L1H5"
      ],
      "metadata": {
        "id": "BkQK5fgbl0_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup:"
      ],
      "metadata": {
        "id": "tDwZTA1Tr4F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import pkg_resources\n",
        "\n",
        "installed_packages = [pkg.key for pkg in pkg_resources.working_set]\n",
        "if \"transformer-lens\" not in installed_packages:\n",
        "    %pip install transformer_lens==2.11.0 einops eindex-callum jaxtyping git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
        "\n",
        "import pandas as pd\n",
        "import circuitsvis as cv\n",
        "import einops\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformer_lens import (\n",
        "    ActivationCache,\n",
        "    FactoredMatrix,\n",
        "    HookedTransformer,\n",
        "    HookedTransformerConfig,\n",
        "    utils,\n",
        ")\n",
        "from transformer_lens.hook_points import HookPoint"
      ],
      "metadata": {
        "id": "oUuoGz1ur6Ct"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random as rand\n",
        "import plotly.express as px\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "ZDpjg9KCMx3P"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Generate input prompt"
      ],
      "metadata": {
        "id": "a63A0WEToMzV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNsmbpepkrtX",
        "outputId": "428489c5-b593-466a-fc43-4e592d3c124c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0        1          2         3       4         5\n",
            "0     dog      cat       fish       rat     bat     horse\n",
            "1     red     blue      green      pink    gray      cyan\n",
            "2     you       he        his       she     her     their\n",
            "3     car      bus        van      taxi    jeep      tram\n",
            "4   Italy  Iceland    Austria    Mexico   Spain    France\n",
            "5     sad      mad       glad     angry    calm     happy\n",
            "6  Monday  Tuesday  Wednesday  Thursday  Friday  Saturday\n",
            "7      69       72         88        68      90        57\n",
            "8    1800     2025       1275      1945    1600      2100\n"
          ]
        }
      ],
      "source": [
        "semantic_words_file = pd.read_csv('semantic_words.csv', header=None)\n",
        "print(semantic_words_file.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create shuffled list of tokens\n",
        "n_sequences = 30\n",
        "n_tokens = 12\n",
        "n_rows = semantic_words_file.shape[0]\n",
        "\n",
        "inputs = np.empty((n_sequences, n_tokens), dtype=tuple)\n",
        "seed:int = 5 # seeds that work: 5\n",
        "rnd = np.random.RandomState(seed)\n",
        "\n",
        "for i in range(n_sequences):\n",
        "  subset = semantic_words_file.sample(4, random_state = rnd)\n",
        "  for j in range(n_tokens):\n",
        "    category_list = subset.sample(1, random_state = rnd)\n",
        "    category = category_list.index[0]\n",
        "    token = category_list.iloc[0].sample(1, random_state = rnd).values[0]\n",
        "    inputs[i, j] = (category, token)\n",
        "# print(inputs)"
      ],
      "metadata": {
        "id": "kPTOFv_Hu2IW",
        "collapsed": true
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create masks representing where tokens in an input share a category\n",
        "masks = np.zeros((n_sequences, n_tokens, n_tokens))\n",
        "\n",
        "for seq in range(n_sequences):\n",
        "  for i in range(n_tokens):\n",
        "    for j in range(n_tokens):\n",
        "      if inputs[seq, i][0] == inputs[seq, j][0] and inputs[seq, i][1] != inputs[seq, j][1] and i > j: # ensures upper triangle is 0s\n",
        "        masks[seq, i, j] = 1"
      ],
      "metadata": {
        "id": "6zq_q0WrXRfg"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_mask = 1\n",
        "fig = px.imshow(masks[show_mask], labels=dict(x=\"Token Index\", y=\"Token Index\", color=\"Same Category\")) # Added labels dictionary\n",
        "fig.update_layout(xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = list(range(n_tokens)),\n",
        "        ticktext = [inputs[show_mask, i][1] for i in range(n_tokens)] # Use tokens from inputs for x-axis\n",
        "    ),\n",
        "    yaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = list(range(n_tokens)),\n",
        "        ticktext = [inputs[show_mask, i][1] for i in range(n_tokens)] # Use tokens from inputs for y-axis\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2qn3t2CVass-",
        "outputId": "26a11671-bcf4-44ca-e5c7-7d7ec8b9662b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d95427b4-f06e-4fc7-b710-d19f3bc75897\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d95427b4-f06e-4fc7-b710-d19f3bc75897\")) {                    Plotly.newPlot(                        \"d95427b4-f06e-4fc7-b710-d19f3bc75897\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0],[0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0],[0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Token Index: %{x}\\u003cbr\\u003eToken Index: %{y}\\u003cbr\\u003eSame Category: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Token Index\"},\"tickmode\":\"array\",\"tickvals\":[0,1,2,3,4,5,6,7,8,9,10,11],\"ticktext\":[\"57\",\"bat\",\"horse\",\"72\",\"1945\",\"cat\",\"bus\",\"1800\",\"1600\",\"dog\",\"cat\",\"2100\"]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Token Index\"},\"tickmode\":\"array\",\"tickvals\":[0,1,2,3,4,5,6,7,8,9,10,11],\"ticktext\":[\"57\",\"bat\",\"horse\",\"72\",\"1945\",\"cat\",\"bus\",\"1800\",\"1600\",\"dog\",\"cat\",\"2100\"]},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Same Category\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d95427b4-f06e-4fc7-b710-d19f3bc75897');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load & test gpt2-small:"
      ],
      "metadata": {
        "id": "QvvWExRYkTdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=\"cpu\")\n",
        "print(model.cfg)"
      ],
      "metadata": {
        "id": "TlwpExqFkZ9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f09f84c5-fe35-4cbd-9354-3546060a2cf7"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n",
            "HookedTransformerConfig:\n",
            "{'NTK_by_parts_factor': 8.0,\n",
            " 'NTK_by_parts_high_freq_factor': 4.0,\n",
            " 'NTK_by_parts_low_freq_factor': 1.0,\n",
            " 'act_fn': 'gelu_new',\n",
            " 'attention_dir': 'causal',\n",
            " 'attn_only': False,\n",
            " 'attn_scale': 8.0,\n",
            " 'attn_scores_soft_cap': -1.0,\n",
            " 'attn_types': None,\n",
            " 'checkpoint_index': None,\n",
            " 'checkpoint_label_type': None,\n",
            " 'checkpoint_value': None,\n",
            " 'd_head': 64,\n",
            " 'd_mlp': 3072,\n",
            " 'd_model': 768,\n",
            " 'd_vocab': 50257,\n",
            " 'd_vocab_out': 50257,\n",
            " 'decoder_start_token_id': None,\n",
            " 'default_prepend_bos': True,\n",
            " 'device': 'cpu',\n",
            " 'dtype': torch.float32,\n",
            " 'eps': 1e-05,\n",
            " 'experts_per_token': None,\n",
            " 'final_rms': False,\n",
            " 'from_checkpoint': False,\n",
            " 'gated_mlp': False,\n",
            " 'init_mode': 'gpt2',\n",
            " 'init_weights': False,\n",
            " 'initializer_range': 0.02886751345948129,\n",
            " 'load_in_4bit': False,\n",
            " 'model_name': 'gpt2',\n",
            " 'n_ctx': 1024,\n",
            " 'n_devices': 1,\n",
            " 'n_heads': 12,\n",
            " 'n_key_value_heads': None,\n",
            " 'n_layers': 12,\n",
            " 'n_params': 84934656,\n",
            " 'normalization_type': 'LNPre',\n",
            " 'num_experts': None,\n",
            " 'original_architecture': 'GPT2LMHeadModel',\n",
            " 'output_logits_soft_cap': -1.0,\n",
            " 'parallel_attn_mlp': False,\n",
            " 'positional_embedding_type': 'standard',\n",
            " 'post_embedding_ln': False,\n",
            " 'relative_attention_max_distance': None,\n",
            " 'relative_attention_num_buckets': None,\n",
            " 'rotary_adjacent_pairs': False,\n",
            " 'rotary_base': 10000,\n",
            " 'rotary_dim': None,\n",
            " 'scale_attn_by_inverse_layer_idx': False,\n",
            " 'seed': None,\n",
            " 'tie_word_embeddings': False,\n",
            " 'tokenizer_name': 'gpt2',\n",
            " 'tokenizer_prepends_bos': False,\n",
            " 'trust_remote_code': False,\n",
            " 'ungroup_grouped_query_attention': False,\n",
            " 'use_NTK_by_parts_rope': False,\n",
            " 'use_attn_in': False,\n",
            " 'use_attn_result': False,\n",
            " 'use_attn_scale': True,\n",
            " 'use_hook_mlp_in': False,\n",
            " 'use_hook_tokens': False,\n",
            " 'use_local_attn': False,\n",
            " 'use_normalization_before_and_after': False,\n",
            " 'use_split_qkv_input': False,\n",
            " 'window_size': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run model on selected sequence & cache activation\n",
        "sequence_index = show_mask\n",
        "test_input = ' '.join([inputs[sequence_index, i][1] for i in range(n_tokens)])\n",
        "print(\"input: \" + test_input)\n",
        "input_tokens = model.to_tokens(test_input)\n",
        "logits, cache = model.run_with_cache(input_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yub7MsEKlDa4",
        "outputId": "3259d08e-3dca-4d32-9ad3-cc3a8427bb92"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: 57 bat horse 72 1945 cat bus 1800 1600 dog cat 2100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_number = 1\n",
        "layer1_patterns = cache[\"pattern\", layer_number]\n",
        "print(layer1_patterns.shape)\n",
        "print(input_tokens.shape)\n",
        "print(input_tokens.squeeze())\n",
        "str_tokens = model.to_str_tokens(input_tokens.squeeze())\n",
        "\n",
        "display(\n",
        "    cv.attention.attention_patterns(\n",
        "        tokens=str_tokens,\n",
        "        attention=layer1_patterns.squeeze(),\n",
        "        attention_head_names=[f\"L{layer_number}H{i}\" for i in range(12)],\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "WtbV05XCm252",
        "outputId": "562b52dd-fb5c-4310-b754-40b42996d908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 12, 13, 13])\n",
            "torch.Size([1, 13])\n",
            "tensor([50256,  3553,  7365,  8223,  7724, 15761,  3797,  1323, 21431, 26143,\n",
            "         3290,  3797, 38123])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7f5e029101d0>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-cd4c7361-3ba3\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-cd4c7361-3ba3\",\n",
              "      AttentionPatterns,\n",
              "      {\"tokens\": [\"<|endoftext|>\", \"57\", \" bat\", \" horse\", \" 72\", \" 1945\", \" cat\", \" bus\", \" 1800\", \" 1600\", \" dog\", \" cat\", \" 2100\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9780283570289612, 0.02197159267961979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4139260947704315, 0.2616051137447357, 0.32446879148483276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2511322796344757, 0.08023326843976974, 0.3357439339160919, 0.33289048075675964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21215707063674927, 0.08877833187580109, 0.17398923635482788, 0.16692112386226654, 0.358154296875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16385619342327118, 0.054668817669153214, 0.054746635258197784, 0.30363091826438904, 0.27676570415496826, 0.14633171260356903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14568151533603668, 0.018722275272011757, 0.1878071427345276, 0.23139670491218567, 0.09503038972616196, 0.10518983006477356, 0.2161722034215927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05320969223976135, 0.019537165760993958, 0.10402766615152359, 0.10773788392543793, 0.09766026586294174, 0.1727868765592575, 0.3507172465324402, 0.09432324767112732, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09119085967540741, 0.025396494194865227, 0.023497406393289566, 0.05825963616371155, 0.17690704762935638, 0.206369087100029, 0.15389159321784973, 0.09614045917987823, 0.16834750771522522, 0.0, 0.0, 0.0, 0.0], [0.07117225974798203, 0.02175821177661419, 0.0254946481436491, 0.039073918014764786, 0.16070255637168884, 0.12256155163049698, 0.07323300838470459, 0.11573795229196548, 0.16465190052986145, 0.2056138962507248, 0.0, 0.0, 0.0], [0.029729247093200684, 0.0034425228368490934, 0.030815934762358665, 0.04426734149456024, 0.03343848139047623, 0.03721775487065315, 0.11446961760520935, 0.14997674524784088, 0.17734698951244354, 0.18981145322322845, 0.1894838511943817, 0.0, 0.0], [0.046085141599178314, 0.0032945412676781416, 0.03446405008435249, 0.04126068577170372, 0.016603680327534676, 0.02224365435540676, 0.04458000883460045, 0.10561831295490265, 0.0701574981212616, 0.08492081612348557, 0.3078967332839966, 0.2228749394416809, 0.0], [0.026248615235090256, 0.004738787189126015, 0.006529774982482195, 0.011766068637371063, 0.04007137566804886, 0.07243212312459946, 0.021230900660157204, 0.026809977367520332, 0.08166035264730453, 0.18200241029262543, 0.09915805608034134, 0.11058812588453293, 0.31676343083381653]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9690414667129517, 0.030958542600274086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7924848794937134, 0.12353559583425522, 0.08397943526506424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6187768578529358, 0.11744000762701035, 0.11485063284635544, 0.1489325314760208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6090797185897827, 0.04610610753297806, 0.07553620636463165, 0.1249731034040451, 0.1443048119544983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4048022925853729, 0.04206850752234459, 0.06533291190862656, 0.10440227389335632, 0.18777592480182648, 0.19561801850795746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33788493275642395, 0.032312266528606415, 0.03553682193160057, 0.05859900638461113, 0.18706242740154266, 0.22499032318592072, 0.12361418455839157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31021755933761597, 0.03199150040745735, 0.03229948878288269, 0.046341296285390854, 0.13133499026298523, 0.18332438170909882, 0.15581238269805908, 0.10867839306592941, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23502789437770844, 0.013206022791564465, 0.03336039558053017, 0.0399189218878746, 0.0787457823753357, 0.13213883340358734, 0.1480799913406372, 0.13029898703098297, 0.18922317028045654, 0.0, 0.0, 0.0, 0.0], [0.175685316324234, 0.00936860777437687, 0.03155381232500076, 0.03256731480360031, 0.05890735983848572, 0.09670881927013397, 0.1195901408791542, 0.12014433741569519, 0.1450154036283493, 0.21045882999897003, 0.0, 0.0, 0.0], [0.1437484174966812, 0.007414936553686857, 0.009298757649958134, 0.01365695707499981, 0.05087389796972275, 0.06662094593048096, 0.03976042568683624, 0.059466153383255005, 0.20574422180652618, 0.2992473840713501, 0.10416790843009949, 0.0, 0.0], [0.1715620756149292, 0.007388576399534941, 0.010393750853836536, 0.014766093343496323, 0.050307705998420715, 0.060944814234972, 0.029030578210949898, 0.05258023366332054, 0.14463667571544647, 0.19662728905677795, 0.10819493979215622, 0.15356726944446564, 0.0], [0.11855407804250717, 0.004300648346543312, 0.010659894905984402, 0.014827794395387173, 0.022883359342813492, 0.03824355825781822, 0.043189868330955505, 0.0374179370701313, 0.061040204018354416, 0.10218705236911774, 0.14369387924671173, 0.25733643770217896, 0.1456652581691742]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9920895099639893, 0.007910482585430145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7821994423866272, 0.028469081968069077, 0.1893315464258194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6521227955818176, 0.025512494146823883, 0.17443877458572388, 0.14792589843273163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5131796002388, 0.02243797853589058, 0.15328921377658844, 0.13019903004169464, 0.18089419603347778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3968636989593506, 0.022367408499121666, 0.1316148191690445, 0.11290361732244492, 0.1554172784090042, 0.18083322048187256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3128434121608734, 0.018368197605013847, 0.11765453219413757, 0.09347767382860184, 0.1285228431224823, 0.15654471516609192, 0.17258861660957336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23661501705646515, 0.017366541549563408, 0.10616526752710342, 0.08687206357717514, 0.10960528254508972, 0.13177689909934998, 0.1535944640636444, 0.158004492521286, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18585115671157837, 0.01673073135316372, 0.08990427851676941, 0.07556818425655365, 0.09392976015806198, 0.11415553092956543, 0.12590932846069336, 0.13997556269168854, 0.1579754650592804, 0.0, 0.0, 0.0, 0.0], [0.15954603254795074, 0.015270060859620571, 0.0774991363286972, 0.06500860303640366, 0.07925505936145782, 0.09646043181419373, 0.10329237580299377, 0.1172623410820961, 0.13317546248435974, 0.15323056280612946, 0.0, 0.0, 0.0], [0.1308736652135849, 0.013121875002980232, 0.06869731098413467, 0.05515449494123459, 0.06683681160211563, 0.08705638349056244, 0.09142028540372849, 0.10359003394842148, 0.11683616042137146, 0.13592050969600677, 0.13049252331256866, 0.0, 0.0], [0.10675905644893646, 0.01284960936754942, 0.06290122866630554, 0.04786345735192299, 0.05829101428389549, 0.07482206076383591, 0.07672389596700668, 0.08914610743522644, 0.09945259243249893, 0.1138550415635109, 0.11444371193647385, 0.14289218187332153, 0.0], [0.09557896852493286, 0.01267879270017147, 0.05512338876724243, 0.04588190093636513, 0.05223570764064789, 0.06648903340101242, 0.06814432144165039, 0.07772219926118851, 0.08754931390285492, 0.10139454901218414, 0.09868911653757095, 0.11998686194419861, 0.11852582544088364]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6055543422698975, 0.39444565773010254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6316828727722168, 0.1554396152496338, 0.21287751197814941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5493198037147522, 0.1190045177936554, 0.17411811649799347, 0.1575576364994049, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5134174823760986, 0.08128435164690018, 0.1328878253698349, 0.12689442932605743, 0.14551591873168945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49611324071884155, 0.06536415219306946, 0.10292265564203262, 0.09810763597488403, 0.11559372395277023, 0.12189853936433792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.48459723591804504, 0.05014648661017418, 0.08586223423480988, 0.0780143067240715, 0.09916997700929642, 0.10850197076797485, 0.09370781481266022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4831809103488922, 0.03949103504419327, 0.06805139780044556, 0.06693871319293976, 0.08303199708461761, 0.09112650156021118, 0.08294259011745453, 0.08523697406053543, 0.0, 0.0, 0.0, 0.0, 0.0], [0.48542550206184387, 0.033020973205566406, 0.0577203668653965, 0.056045010685920715, 0.06749221682548523, 0.07729960978031158, 0.06498201191425323, 0.07207190990447998, 0.08594246208667755, 0.0, 0.0, 0.0, 0.0], [0.4676890969276428, 0.028343811631202698, 0.05130288377404213, 0.04830336570739746, 0.05860123038291931, 0.06830483675003052, 0.05639750510454178, 0.06442499905824661, 0.07675593346357346, 0.07987628132104874, 0.0, 0.0, 0.0], [0.4953403174877167, 0.021150805056095123, 0.041986096650362015, 0.03735953941941261, 0.04759717732667923, 0.05480187013745308, 0.0471552349627018, 0.0530305877327919, 0.0645427405834198, 0.0690791979432106, 0.0679563656449318, 0.0, 0.0], [0.5224719047546387, 0.017156265676021576, 0.034814219921827316, 0.030033716931939125, 0.039125170558691025, 0.04613586142659187, 0.037860553711652756, 0.04507000371813774, 0.051672715693712234, 0.055959925055503845, 0.0586535669863224, 0.061046116054058075, 0.0], [0.4873931407928467, 0.017553482204675674, 0.032818976789712906, 0.03077920898795128, 0.035977739840745926, 0.04315238818526268, 0.035809461027383804, 0.03904885798692703, 0.04879853129386902, 0.0513090081512928, 0.05510232225060463, 0.05583995580673218, 0.06641688942909241]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8987060785293579, 0.10129392892122269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7577760815620422, 0.0879574567079544, 0.15426641702651978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6833850741386414, 0.07139310240745544, 0.1242554783821106, 0.1209663674235344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5711500644683838, 0.08440977334976196, 0.12156489491462708, 0.1195639967918396, 0.10331131517887115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5189758539199829, 0.07472784072160721, 0.10828760266304016, 0.10234803706407547, 0.09375181049108505, 0.10190889984369278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5144063234329224, 0.05120249465107918, 0.09333784878253937, 0.08464572578668594, 0.07231670618057251, 0.08287684619426727, 0.10121405869722366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4546753168106079, 0.046539101749658585, 0.08527512848377228, 0.07804904133081436, 0.06224147602915764, 0.07479449361562729, 0.09809178858995438, 0.10033370554447174, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4213676452636719, 0.04746105894446373, 0.06838560849428177, 0.06670510768890381, 0.06396939605474472, 0.07570682466030121, 0.07852452248334885, 0.08117826282978058, 0.09670161455869675, 0.0, 0.0, 0.0, 0.0], [0.3613242208957672, 0.04743129014968872, 0.06708420068025589, 0.06452779471874237, 0.05872102081775665, 0.06893302500247955, 0.07161600887775421, 0.0726504772901535, 0.0882282704114914, 0.09948369860649109, 0.0, 0.0, 0.0], [0.3667421042919159, 0.03200604394078255, 0.06099141761660576, 0.057070888578891754, 0.04624687880277634, 0.055560264736413956, 0.07119192183017731, 0.0671321451663971, 0.07009169459342957, 0.07972320914268494, 0.09324345737695694, 0.0, 0.0], [0.35065531730651855, 0.0302386786788702, 0.054710712283849716, 0.04880976676940918, 0.04196615517139435, 0.0485135056078434, 0.05940337851643562, 0.057813066989183426, 0.06385543942451477, 0.0727091059088707, 0.08035916835069656, 0.09096565842628479, 0.0], [0.2895498275756836, 0.03888871148228645, 0.05342867597937584, 0.05023675784468651, 0.0442572757601738, 0.050826940685510635, 0.056132249534130096, 0.055246204137802124, 0.06368303298950195, 0.07277131080627441, 0.0696800947189331, 0.07515823096036911, 0.08014070987701416]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.788772702217102, 0.21122726798057556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9407083988189697, 0.03544824570417404, 0.02384337969124317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5446788668632507, 0.05982290580868721, 0.3191770911216736, 0.07632113248109818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4912855923175812, 0.3679587244987488, 0.008742623962461948, 0.009715323336422443, 0.12229777127504349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3587966859340668, 0.2927001714706421, 0.011442256160080433, 0.0295263584703207, 0.06283577531576157, 0.2446986734867096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4953906834125519, 0.008728442713618279, 0.20714721083641052, 0.2130616307258606, 0.01415756531059742, 0.00821011047810316, 0.053304292261600494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.46748465299606323, 0.024560756981372833, 0.0878165140748024, 0.21923021972179413, 0.02233271114528179, 0.017035821452736855, 0.07066566497087479, 0.09087377041578293, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4684738516807556, 0.060545921325683594, 0.021517498418688774, 0.01988747902214527, 0.0745377168059349, 0.1087101474404335, 0.0027534221298992634, 0.01443454809486866, 0.22913941740989685, 0.0, 0.0, 0.0, 0.0], [0.40835651755332947, 0.03593403473496437, 0.010838769376277924, 0.01786685548722744, 0.017845619469881058, 0.0732230618596077, 0.0011471069883555174, 0.0069614253006875515, 0.2811422348022461, 0.146684467792511, 0.0, 0.0, 0.0], [0.10379482060670853, 0.017137739807367325, 0.18991568684577942, 0.22742323577404022, 0.0040941787883639336, 0.0023236346896737814, 0.39474809169769287, 0.03004618175327778, 0.0011390096042305231, 0.003583276644349098, 0.02579410746693611, 0.0, 0.0], [0.16937699913978577, 0.002840024419128895, 0.13800500333309174, 0.14839231967926025, 0.005902878474444151, 0.005113241262733936, 0.05392385646700859, 0.05047398805618286, 0.000899581122212112, 0.0008623028988949955, 0.37389281392097473, 0.05031706765294075, 0.0], [0.21277955174446106, 0.031048599630594254, 0.011087941937148571, 0.010863147675991058, 0.02387586049735546, 0.07336793094873428, 0.0017316072480753064, 0.008760713040828705, 0.27699097990989685, 0.3020659387111664, 0.0009666477562859654, 0.0009680550429038703, 0.04549302160739899]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.958698034286499, 0.04130199924111366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8441265225410461, 0.1414901316165924, 0.014383360743522644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8059636354446411, 0.059260059148073196, 0.03665212169289589, 0.09812412410974503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7664218544960022, 0.17123647034168243, 0.014776520431041718, 0.005963522475212812, 0.04160168394446373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6014835238456726, 0.18670901656150818, 0.00787174329161644, 0.004227933008223772, 0.05139339715242386, 0.14831428229808807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7453277111053467, 0.05915133282542229, 0.04344271868467331, 0.07746756821870804, 0.016550347208976746, 0.012655401602387428, 0.045404985547065735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7379754185676575, 0.07676161825656891, 0.012963153421878815, 0.03566355258226395, 0.043580491095781326, 0.03858925774693489, 0.0027751117013394833, 0.051691386848688126, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5984916687011719, 0.180470809340477, 0.023319417610764503, 0.010304323397576809, 0.11556396633386612, 0.020943976938724518, 0.005977466702461243, 0.02563818357884884, 0.01929028332233429, 0.0, 0.0, 0.0, 0.0], [0.6654428243637085, 0.15974004566669464, 0.010748847387731075, 0.003298455849289894, 0.10232370346784592, 0.010030203498899937, 0.0013399148592725396, 0.006454510614275932, 0.0157286636531353, 0.02489285171031952, 0.0, 0.0, 0.0], [0.561876654624939, 0.08677959442138672, 0.07289145886898041, 0.06122488155961037, 0.042821403592824936, 0.03133109584450722, 0.04164297506213188, 0.0038867180701345205, 0.03615398332476616, 0.01825581304728985, 0.04313547909259796, 0.0, 0.0], [0.5649037957191467, 0.0518571138381958, 0.04967951029539108, 0.09489027410745621, 0.01867150142788887, 0.011699489317834377, 0.07220679521560669, 0.005111063830554485, 0.018670016899704933, 0.012370981276035309, 0.059683769941329956, 0.040255650877952576, 0.0], [0.5541850328445435, 0.1949053406715393, 0.01534141693264246, 0.006980499252676964, 0.15543417632579803, 0.008779529482126236, 0.005596563220024109, 0.011149286292493343, 0.00884291809052229, 0.013160825707018375, 0.003059725509956479, 0.0021106828935444355, 0.0204539205878973]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9161189198493958, 0.08388099819421768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8634806275367737, 0.07663614302873611, 0.05988320708274841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7629571557044983, 0.11357036232948303, 0.09524330496788025, 0.02822914719581604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5676018595695496, 0.12252470850944519, 0.10878158360719681, 0.10130934417247772, 0.0997825637459755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.654973030090332, 0.044869374483823776, 0.1281605064868927, 0.08828149735927582, 0.05355911701917648, 0.030156411230564117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6099822521209717, 0.05334920063614845, 0.04959748312830925, 0.06118226796388626, 0.04153236374258995, 0.17174161970615387, 0.012614773586392403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4826276898384094, 0.05414643511176109, 0.17172059416770935, 0.0737118050456047, 0.037347447127103806, 0.1213986724615097, 0.046855319291353226, 0.012192045338451862, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47792139649391174, 0.05171947553753853, 0.05873187631368637, 0.042769383639097214, 0.05212027207016945, 0.1320350468158722, 0.058004092425107956, 0.0894395112991333, 0.0372590497136116, 0.0, 0.0, 0.0, 0.0], [0.4151034355163574, 0.05622675269842148, 0.07487374544143677, 0.051328759640455246, 0.06072971597313881, 0.11919906735420227, 0.0615270659327507, 0.09369659423828125, 0.03718610852956772, 0.030128801241517067, 0.0, 0.0, 0.0], [0.4284398853778839, 0.03713677078485489, 0.04522823542356491, 0.036769211292266846, 0.031567759811878204, 0.1506117433309555, 0.014248020015656948, 0.08126110583543777, 0.06247521564364433, 0.09682522714138031, 0.015436784364283085, 0.0, 0.0], [0.4751906991004944, 0.03872670233249664, 0.036501456052064896, 0.04094095528125763, 0.031687505543231964, 0.1493469923734665, 0.007910903543233871, 0.06741480529308319, 0.054896242916584015, 0.08062336593866348, 0.01255987212061882, 0.004200449679046869, 0.0], [0.3690912425518036, 0.04584724083542824, 0.072306327521801, 0.04724130034446716, 0.05199190601706505, 0.08457358181476593, 0.06024470180273056, 0.06160706281661987, 0.0339871309697628, 0.03398068994283676, 0.06833408027887344, 0.03690998628735542, 0.03388473764061928]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9030750393867493, 0.09692496806383133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7490968108177185, 0.13679152727127075, 0.11411166936159134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.602368175983429, 0.14667002856731415, 0.15534843504428864, 0.09561330825090408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6682213544845581, 0.08475709706544876, 0.08786412328481674, 0.07653465867042542, 0.08262281119823456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5212184190750122, 0.09026248753070831, 0.11120641976594925, 0.09597128629684448, 0.10475976020097733, 0.07658156007528305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5389868021011353, 0.09078241139650345, 0.07710311561822891, 0.06843256205320358, 0.0806136205792427, 0.0710572600364685, 0.07302418351173401, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5321751236915588, 0.08177515864372253, 0.06806723773479462, 0.05767447501420975, 0.06703443825244904, 0.05020428076386452, 0.07984673231840134, 0.06322263181209564, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4927615523338318, 0.06361878663301468, 0.06412073969841003, 0.07512678951025009, 0.06457094103097916, 0.05939049646258354, 0.06993915885686874, 0.05883457884192467, 0.05163700133562088, 0.0, 0.0, 0.0, 0.0], [0.4589298963546753, 0.06264322251081467, 0.061906423419713974, 0.07653025537729263, 0.06624989211559296, 0.05113445222377777, 0.07598558068275452, 0.05148646607995033, 0.04314110800623894, 0.05199269577860832, 0.0, 0.0, 0.0], [0.43583986163139343, 0.05925041064620018, 0.05685006082057953, 0.05729056894779205, 0.05570738762617111, 0.04398904740810394, 0.06662984192371368, 0.055676188319921494, 0.04473632574081421, 0.06390853226184845, 0.06012171506881714, 0.0, 0.0], [0.4633840322494507, 0.04872109368443489, 0.044393640011548996, 0.052108198404312134, 0.04769815132021904, 0.04076099768280983, 0.05114404484629631, 0.04719623178243637, 0.03875560313463211, 0.05186840519309044, 0.05305087938904762, 0.060918666422367096, 0.0], [0.40863698720932007, 0.045229144394397736, 0.0458526648581028, 0.06011296808719635, 0.04540947824716568, 0.042776234447956085, 0.05623248219490051, 0.04612486809492111, 0.038318533450365067, 0.04863966256380081, 0.055990058928728104, 0.06580615788698196, 0.0408707819879055]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9340165257453918, 0.06598343700170517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.895546555519104, 0.0798487663269043, 0.024604616686701775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8411579728126526, 0.08634869754314423, 0.0354083813726902, 0.03708486631512642, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7919489741325378, 0.07511729747056961, 0.031988006085157394, 0.036342330276966095, 0.06460349261760712, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6736294031143188, 0.08869015425443649, 0.04768696799874306, 0.03834366425871849, 0.07563536614179611, 0.07601440697908401, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6630635261535645, 0.08778566122055054, 0.03350674360990524, 0.04736720025539398, 0.053688760846853256, 0.06584201008081436, 0.04874611645936966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6183016300201416, 0.09499967098236084, 0.0378735214471817, 0.04426977038383484, 0.0688956007361412, 0.03213075175881386, 0.07333506643772125, 0.030193964019417763, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5778323411941528, 0.06665734201669693, 0.033883269876241684, 0.04101952910423279, 0.0596843957901001, 0.06205277889966965, 0.07050888985395432, 0.04409917816519737, 0.044262245297431946, 0.0, 0.0, 0.0, 0.0], [0.568473219871521, 0.06944723427295685, 0.03033171221613884, 0.0406273752450943, 0.0581284798681736, 0.043512385338544846, 0.06572961062192917, 0.040950626134872437, 0.043052248656749725, 0.03974716737866402, 0.0, 0.0, 0.0], [0.4479370713233948, 0.07807820290327072, 0.05319046601653099, 0.06320536136627197, 0.04774260148406029, 0.0439632348716259, 0.07828910648822784, 0.03982296213507652, 0.039136871695518494, 0.041109565645456314, 0.06752454489469528, 0.0, 0.0], [0.3946629464626312, 0.08152145147323608, 0.043079107999801636, 0.05751502513885498, 0.05309787765145302, 0.05314603075385094, 0.05311676859855652, 0.04730036482214928, 0.05115224048495293, 0.045385781675577164, 0.0654858872294426, 0.05453651025891304, 0.0], [0.4168451130390167, 0.06852466613054276, 0.039780400693416595, 0.04527094215154648, 0.06456916779279709, 0.033733900636434555, 0.05775659158825874, 0.036114178597927094, 0.045909374952316284, 0.048295993357896805, 0.043332673609256744, 0.05793693661689758, 0.041929975152015686]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000407343206461519, 0.9995927214622498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010840566828846931, 0.43307945132255554, 0.5658365488052368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0009047770872712135, 0.2737787961959839, 0.3780435621738434, 0.3472728133201599, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001208305126056075, 0.1749136745929718, 0.2798115015029907, 0.24903373420238495, 0.2950328588485718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013626705622300506, 0.13590991497039795, 0.20759764313697815, 0.18667441606521606, 0.22970294952392578, 0.23875243961811066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001075345790013671, 0.10251197963953018, 0.17400766909122467, 0.15158899128437042, 0.18747417628765106, 0.21277813613414764, 0.17056362330913544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0015089790103957057, 0.08061352372169495, 0.13958071172237396, 0.1286897361278534, 0.15103445947170258, 0.17934401333332062, 0.1480989009141922, 0.1711297333240509, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001922078081406653, 0.06356573104858398, 0.11310184746980667, 0.102226622402668, 0.13035359978675842, 0.14413027465343475, 0.11771267652511597, 0.14707058668136597, 0.17991657555103302, 0.0, 0.0, 0.0, 0.0], [0.00205954909324646, 0.05261175334453583, 0.0950876846909523, 0.08613510429859161, 0.10892391204833984, 0.12252561748027802, 0.09656862169504166, 0.12321796268224716, 0.15114182233810425, 0.16172796487808228, 0.0, 0.0, 0.0], [0.0019133458845317364, 0.04174196720123291, 0.08052143454551697, 0.07080782949924469, 0.08911019563674927, 0.10481393337249756, 0.08457311242818832, 0.10485566407442093, 0.1340816169977188, 0.14937037229537964, 0.1382105052471161, 0.0, 0.0], [0.0024529453366994858, 0.03521134331822395, 0.06949249655008316, 0.06068615987896919, 0.07795042544603348, 0.09421411901712418, 0.07147621363401413, 0.08996789902448654, 0.12027916312217712, 0.1322324126958847, 0.1256096214056015, 0.12042722851037979, 0.0], [0.0026164560113102198, 0.03343576565384865, 0.06227736175060272, 0.055274028331041336, 0.06911152601242065, 0.07947307825088501, 0.062493324279785156, 0.07881160080432892, 0.09858760237693787, 0.10613569617271423, 0.10142723470926285, 0.09842851012945175, 0.15192776918411255]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30445149540901184, 0.6955485343933105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13705240190029144, 0.002584150293841958, 0.8603634238243103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12867975234985352, 0.005551674868911505, 0.03682691231369972, 0.8289417028427124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09866048395633698, 0.010553145781159401, 0.0024170379620045424, 0.00025934766745194793, 0.8881099820137024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16118021309375763, 0.014393077231943607, 0.009353998117148876, 0.0077461740002036095, 0.0038324056658893824, 0.8034940958023071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14756232500076294, 0.008103525266051292, 0.07165094465017319, 0.04211818799376488, 0.002445217687636614, 0.003352060914039612, 0.724767804145813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12379991263151169, 0.0012846968602389097, 0.01931176520884037, 0.004978209733963013, 0.008247210644185543, 0.0009119583410210907, 0.0029417455662041903, 0.838524580001831, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08953560888767242, 0.004128703381866217, 0.000995089067146182, 0.0009766750736162066, 0.006318171974271536, 0.014701002277433872, 0.0002386552660027519, 0.001482438761740923, 0.8816236853599548, 0.0, 0.0, 0.0, 0.0], [0.06561972945928574, 0.00258853891864419, 0.001049520680680871, 0.0008403644314967096, 0.0010678238468244672, 0.013605031184852123, 0.0003049163206014782, 0.0007574576302431524, 0.06833548098802567, 0.8458310961723328, 0.0, 0.0, 0.0], [0.13987059891223907, 0.014596717432141304, 0.06417037546634674, 0.153837189078331, 0.0026985483709722757, 0.006266604643315077, 0.09546925127506256, 0.008846612647175789, 0.001432341057807207, 0.0016872144769877195, 0.5111245512962341, 0.0, 0.0], [0.04472803324460983, 0.00348282721824944, 0.039796195924282074, 0.030854254961013794, 0.0010732938535511494, 0.0020166640169918537, 0.45925799012184143, 0.0034830530639737844, 0.0002863655099645257, 0.0010915971361100674, 0.02224639430642128, 0.39168334007263184, 0.0], [0.21995221078395844, 0.0028405471239238977, 0.001410383847542107, 0.0014644099865108728, 0.01872294582426548, 0.008935527876019478, 0.00026618907577358186, 0.0042147464118897915, 0.11578912287950516, 0.0936976745724678, 0.00028070135158486664, 0.00010906893294304609, 0.5323165059089661]]], \"headLabels\": [\"L1H0\", \"L1H1\", \"L1H2\", \"L1H3\", \"L1H4\", \"L1H5\", \"L1H6\", \"L1H7\", \"L1H8\", \"L1H9\", \"L1H10\", \"L1H11\"]}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pattern detector:"
      ],
      "metadata": {
        "id": "HW1HJh0ITDjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"layers: {model.cfg.n_layers}\")\n",
        "print(f\"heads per layer: {model.cfg.n_heads}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmgi9TYtTesU",
        "outputId": "eb8d1b21-1f6f-4e3d-89a8-428e343baf09"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers: 12\n",
            "heads per layer: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_semantic_head(cache: ActivationCache, layer:int, head:int):\n",
        "  attention_pattern = cache[\"pattern\", layer].squeeze()[head]\n",
        "  expected_attention = attention_pattern[1:,1:][t.from_numpy(masks[sequence_index]).bool()] # slice attention to ignore |endoftext| and then apply mask\n",
        "  return t.mean(expected_attention)\n",
        "\n",
        "def semantic_head_detector(cache: ActivationCache):\n",
        "  scores = np.zeros((model.cfg.n_layers, model.cfg.n_heads))\n",
        "\n",
        "  # calculate attention score for current input for each attention head\n",
        "  for layer in range(model.cfg.n_layers):\n",
        "    for head in range(model.cfg.n_heads):\n",
        "      scores[layer, head] = evaluate_semantic_head(cache, layer, head)\n",
        "  return scores\n"
      ],
      "metadata": {
        "id": "iIuPQ2N2TQPE"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_head_scores = semantic_head_detector(cache)\n",
        "fig = px.imshow(attn_head_scores, labels=dict(x=\"Head\", y=\"Layer\", color=\"Attention Score\"))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "zWL-cDBZZYaJ",
        "collapsed": true,
        "outputId": "b080e55f-3c39-45ce-ddde-0e4707a17348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"06a2efac-48ae-42b3-a2c7-0debddd5bb96\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"06a2efac-48ae-42b3-a2c7-0debddd5bb96\")) {                    Plotly.newPlot(                        \"06a2efac-48ae-42b3-a2c7-0debddd5bb96\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.14556486904621124,0.00580415828153491,0.05023669824004173,0.014831479638814926,0.049077052623033524,0.0013364505721256137,0.1430930346250534,0.08571596443653107,0.13142722845077515,0.06865386664867401,0.09020480513572693,0.08945930004119873],[0.1404111236333847,0.06415608525276184,0.09048211574554443,0.06468135863542557,0.07374575734138489,0.23095136880874634,0.04914361983537674,0.05973482131958008,0.06246030330657959,0.05179508030414581,0.1295149177312851,0.055161669850349426],[0.08914428949356079,0.025406040251255035,0.08185222744941711,0.06116776540875435,0.03230408951640129,0.05182050168514252,0.06286334991455078,0.10007112473249435,0.10627414286136627,0.07408614456653595,0.10397873818874359,0.03768065571784973],[0.011613555252552032,0.058553844690322876,0.05435500666499138,0.07762163877487183,0.1396482139825821,0.04272238165140152,0.08414790779352188,0.09279359877109528,0.042653001844882965,0.05407336354255676,0.0598963126540184,0.057421401143074036],[0.010519545525312424,0.03528912365436554,0.05257101729512215,0.050956401973962784,0.07518871128559113,0.03133498132228851,0.06655888259410858,0.08828721195459366,0.07440319657325745,0.04942338168621063,0.045685432851314545,0.18721997737884521],[0.07006113231182098,0.02056843973696232,0.04738098755478859,0.0780472680926323,0.048769500106573105,0.05274759232997894,0.13584639132022858,0.007676856592297554,0.03215843066573143,0.052784234285354614,0.07494360953569412,0.038386132568120956],[0.09401914477348328,0.021090174093842506,0.022082779556512833,0.03162034973502159,0.046564843505620956,0.05076669156551361,0.06274142116308212,0.06888410449028015,0.10694753378629684,0.10773304104804993,0.03567761927843094,0.04310464486479759],[0.09632646292448044,0.04330337792634964,0.022872790694236755,0.03889378905296326,0.0175301656126976,0.0352560393512249,0.05268266052007675,0.034142106771469116,0.03122311644256115,0.011696841567754745,0.05698709934949875,0.10346923768520355],[0.02403712458908558,0.098078653216362,0.04777666926383972,0.0267997644841671,0.00501948781311512,0.05299261212348938,0.10388752818107605,0.061259157955646515,0.06425343453884125,0.04480458050966263,0.027079354971647263,0.04624883458018303],[0.028503332287073135,0.03991057351231575,0.03408579155802727,0.06173212081193924,0.030089586973190308,0.01661945879459381,0.06467798352241516,0.04330055043101311,0.024552680552005768,0.029968850314617157,0.01388491690158844,0.05559305474162102],[0.05906149744987488,0.05332013964653015,0.043757326900959015,0.12222276628017426,0.04670283943414688,0.030364718288183212,0.023785557597875595,0.06636113673448563,0.04792426899075508,0.028881873935461044,0.03832376003265381,0.07443689554929733],[0.12759926915168762,0.06307155638933182,0.08093488216400146,0.07726879417896271,0.05491223186254501,0.055152423679828644,0.0434509702026844,0.06095020845532417,0.15981173515319824,0.0763341635465622,0.05233367532491684,0.044136811047792435]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003eAttention Score: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Attention Score\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('06a2efac-48ae-42b3-a2c7-0debddd5bb96');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Measuring Component importance:\n",
        "In order to measure which components are contributing to the function of L1H5, we perform a mean ablation study. We replace each previous compenent of the network with its mean and re-measure the attention score of our metric for L1H5 to see if it was impacted by the ablation of that component. The components which when ablated has the most effect on the performance of L1H5 are the components which contribute to its function."
      ],
      "metadata": {
        "id": "e0RW1Cvj2Jzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embed_name = utils.get_act_name(\"pos\")\n",
        "print(model.W_pos.size())\n",
        "print(model.hook_dict) # print hookpoint names"
      ],
      "metadata": {
        "id": "ABM3-pPL_6NS",
        "outputId": "bf58a0ae-9082-4a2b-8a0c-5cb8371df335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1024, 768])\n",
            "{'hook_embed': HookPoint(), 'hook_pos_embed': HookPoint(), 'blocks.0.ln1.hook_scale': HookPoint(), 'blocks.0.ln1.hook_normalized': HookPoint(), 'blocks.0.ln2.hook_scale': HookPoint(), 'blocks.0.ln2.hook_normalized': HookPoint(), 'blocks.0.attn.hook_k': HookPoint(), 'blocks.0.attn.hook_q': HookPoint(), 'blocks.0.attn.hook_v': HookPoint(), 'blocks.0.attn.hook_z': HookPoint(), 'blocks.0.attn.hook_attn_scores': HookPoint(), 'blocks.0.attn.hook_pattern': HookPoint(), 'blocks.0.attn.hook_result': HookPoint(), 'blocks.0.mlp.hook_pre': HookPoint(), 'blocks.0.mlp.hook_post': HookPoint(), 'blocks.0.hook_attn_in': HookPoint(), 'blocks.0.hook_q_input': HookPoint(), 'blocks.0.hook_k_input': HookPoint(), 'blocks.0.hook_v_input': HookPoint(), 'blocks.0.hook_mlp_in': HookPoint(), 'blocks.0.hook_attn_out': HookPoint(), 'blocks.0.hook_mlp_out': HookPoint(), 'blocks.0.hook_resid_pre': HookPoint(), 'blocks.0.hook_resid_mid': HookPoint(), 'blocks.0.hook_resid_post': HookPoint(), 'blocks.1.ln1.hook_scale': HookPoint(), 'blocks.1.ln1.hook_normalized': HookPoint(), 'blocks.1.ln2.hook_scale': HookPoint(), 'blocks.1.ln2.hook_normalized': HookPoint(), 'blocks.1.attn.hook_k': HookPoint(), 'blocks.1.attn.hook_q': HookPoint(), 'blocks.1.attn.hook_v': HookPoint(), 'blocks.1.attn.hook_z': HookPoint(), 'blocks.1.attn.hook_attn_scores': HookPoint(), 'blocks.1.attn.hook_pattern': HookPoint(), 'blocks.1.attn.hook_result': HookPoint(), 'blocks.1.mlp.hook_pre': HookPoint(), 'blocks.1.mlp.hook_post': HookPoint(), 'blocks.1.hook_attn_in': HookPoint(), 'blocks.1.hook_q_input': HookPoint(), 'blocks.1.hook_k_input': HookPoint(), 'blocks.1.hook_v_input': HookPoint(), 'blocks.1.hook_mlp_in': HookPoint(), 'blocks.1.hook_attn_out': HookPoint(), 'blocks.1.hook_mlp_out': HookPoint(), 'blocks.1.hook_resid_pre': HookPoint(), 'blocks.1.hook_resid_mid': HookPoint(), 'blocks.1.hook_resid_post': HookPoint(), 'blocks.2.ln1.hook_scale': HookPoint(), 'blocks.2.ln1.hook_normalized': HookPoint(), 'blocks.2.ln2.hook_scale': HookPoint(), 'blocks.2.ln2.hook_normalized': HookPoint(), 'blocks.2.attn.hook_k': HookPoint(), 'blocks.2.attn.hook_q': HookPoint(), 'blocks.2.attn.hook_v': HookPoint(), 'blocks.2.attn.hook_z': HookPoint(), 'blocks.2.attn.hook_attn_scores': HookPoint(), 'blocks.2.attn.hook_pattern': HookPoint(), 'blocks.2.attn.hook_result': HookPoint(), 'blocks.2.mlp.hook_pre': HookPoint(), 'blocks.2.mlp.hook_post': HookPoint(), 'blocks.2.hook_attn_in': HookPoint(), 'blocks.2.hook_q_input': HookPoint(), 'blocks.2.hook_k_input': HookPoint(), 'blocks.2.hook_v_input': HookPoint(), 'blocks.2.hook_mlp_in': HookPoint(), 'blocks.2.hook_attn_out': HookPoint(), 'blocks.2.hook_mlp_out': HookPoint(), 'blocks.2.hook_resid_pre': HookPoint(), 'blocks.2.hook_resid_mid': HookPoint(), 'blocks.2.hook_resid_post': HookPoint(), 'blocks.3.ln1.hook_scale': HookPoint(), 'blocks.3.ln1.hook_normalized': HookPoint(), 'blocks.3.ln2.hook_scale': HookPoint(), 'blocks.3.ln2.hook_normalized': HookPoint(), 'blocks.3.attn.hook_k': HookPoint(), 'blocks.3.attn.hook_q': HookPoint(), 'blocks.3.attn.hook_v': HookPoint(), 'blocks.3.attn.hook_z': HookPoint(), 'blocks.3.attn.hook_attn_scores': HookPoint(), 'blocks.3.attn.hook_pattern': HookPoint(), 'blocks.3.attn.hook_result': HookPoint(), 'blocks.3.mlp.hook_pre': HookPoint(), 'blocks.3.mlp.hook_post': HookPoint(), 'blocks.3.hook_attn_in': HookPoint(), 'blocks.3.hook_q_input': HookPoint(), 'blocks.3.hook_k_input': HookPoint(), 'blocks.3.hook_v_input': HookPoint(), 'blocks.3.hook_mlp_in': HookPoint(), 'blocks.3.hook_attn_out': HookPoint(), 'blocks.3.hook_mlp_out': HookPoint(), 'blocks.3.hook_resid_pre': HookPoint(), 'blocks.3.hook_resid_mid': HookPoint(), 'blocks.3.hook_resid_post': HookPoint(), 'blocks.4.ln1.hook_scale': HookPoint(), 'blocks.4.ln1.hook_normalized': HookPoint(), 'blocks.4.ln2.hook_scale': HookPoint(), 'blocks.4.ln2.hook_normalized': HookPoint(), 'blocks.4.attn.hook_k': HookPoint(), 'blocks.4.attn.hook_q': HookPoint(), 'blocks.4.attn.hook_v': HookPoint(), 'blocks.4.attn.hook_z': HookPoint(), 'blocks.4.attn.hook_attn_scores': HookPoint(), 'blocks.4.attn.hook_pattern': HookPoint(), 'blocks.4.attn.hook_result': HookPoint(), 'blocks.4.mlp.hook_pre': HookPoint(), 'blocks.4.mlp.hook_post': HookPoint(), 'blocks.4.hook_attn_in': HookPoint(), 'blocks.4.hook_q_input': HookPoint(), 'blocks.4.hook_k_input': HookPoint(), 'blocks.4.hook_v_input': HookPoint(), 'blocks.4.hook_mlp_in': HookPoint(), 'blocks.4.hook_attn_out': HookPoint(), 'blocks.4.hook_mlp_out': HookPoint(), 'blocks.4.hook_resid_pre': HookPoint(), 'blocks.4.hook_resid_mid': HookPoint(), 'blocks.4.hook_resid_post': HookPoint(), 'blocks.5.ln1.hook_scale': HookPoint(), 'blocks.5.ln1.hook_normalized': HookPoint(), 'blocks.5.ln2.hook_scale': HookPoint(), 'blocks.5.ln2.hook_normalized': HookPoint(), 'blocks.5.attn.hook_k': HookPoint(), 'blocks.5.attn.hook_q': HookPoint(), 'blocks.5.attn.hook_v': HookPoint(), 'blocks.5.attn.hook_z': HookPoint(), 'blocks.5.attn.hook_attn_scores': HookPoint(), 'blocks.5.attn.hook_pattern': HookPoint(), 'blocks.5.attn.hook_result': HookPoint(), 'blocks.5.mlp.hook_pre': HookPoint(), 'blocks.5.mlp.hook_post': HookPoint(), 'blocks.5.hook_attn_in': HookPoint(), 'blocks.5.hook_q_input': HookPoint(), 'blocks.5.hook_k_input': HookPoint(), 'blocks.5.hook_v_input': HookPoint(), 'blocks.5.hook_mlp_in': HookPoint(), 'blocks.5.hook_attn_out': HookPoint(), 'blocks.5.hook_mlp_out': HookPoint(), 'blocks.5.hook_resid_pre': HookPoint(), 'blocks.5.hook_resid_mid': HookPoint(), 'blocks.5.hook_resid_post': HookPoint(), 'blocks.6.ln1.hook_scale': HookPoint(), 'blocks.6.ln1.hook_normalized': HookPoint(), 'blocks.6.ln2.hook_scale': HookPoint(), 'blocks.6.ln2.hook_normalized': HookPoint(), 'blocks.6.attn.hook_k': HookPoint(), 'blocks.6.attn.hook_q': HookPoint(), 'blocks.6.attn.hook_v': HookPoint(), 'blocks.6.attn.hook_z': HookPoint(), 'blocks.6.attn.hook_attn_scores': HookPoint(), 'blocks.6.attn.hook_pattern': HookPoint(), 'blocks.6.attn.hook_result': HookPoint(), 'blocks.6.mlp.hook_pre': HookPoint(), 'blocks.6.mlp.hook_post': HookPoint(), 'blocks.6.hook_attn_in': HookPoint(), 'blocks.6.hook_q_input': HookPoint(), 'blocks.6.hook_k_input': HookPoint(), 'blocks.6.hook_v_input': HookPoint(), 'blocks.6.hook_mlp_in': HookPoint(), 'blocks.6.hook_attn_out': HookPoint(), 'blocks.6.hook_mlp_out': HookPoint(), 'blocks.6.hook_resid_pre': HookPoint(), 'blocks.6.hook_resid_mid': HookPoint(), 'blocks.6.hook_resid_post': HookPoint(), 'blocks.7.ln1.hook_scale': HookPoint(), 'blocks.7.ln1.hook_normalized': HookPoint(), 'blocks.7.ln2.hook_scale': HookPoint(), 'blocks.7.ln2.hook_normalized': HookPoint(), 'blocks.7.attn.hook_k': HookPoint(), 'blocks.7.attn.hook_q': HookPoint(), 'blocks.7.attn.hook_v': HookPoint(), 'blocks.7.attn.hook_z': HookPoint(), 'blocks.7.attn.hook_attn_scores': HookPoint(), 'blocks.7.attn.hook_pattern': HookPoint(), 'blocks.7.attn.hook_result': HookPoint(), 'blocks.7.mlp.hook_pre': HookPoint(), 'blocks.7.mlp.hook_post': HookPoint(), 'blocks.7.hook_attn_in': HookPoint(), 'blocks.7.hook_q_input': HookPoint(), 'blocks.7.hook_k_input': HookPoint(), 'blocks.7.hook_v_input': HookPoint(), 'blocks.7.hook_mlp_in': HookPoint(), 'blocks.7.hook_attn_out': HookPoint(), 'blocks.7.hook_mlp_out': HookPoint(), 'blocks.7.hook_resid_pre': HookPoint(), 'blocks.7.hook_resid_mid': HookPoint(), 'blocks.7.hook_resid_post': HookPoint(), 'blocks.8.ln1.hook_scale': HookPoint(), 'blocks.8.ln1.hook_normalized': HookPoint(), 'blocks.8.ln2.hook_scale': HookPoint(), 'blocks.8.ln2.hook_normalized': HookPoint(), 'blocks.8.attn.hook_k': HookPoint(), 'blocks.8.attn.hook_q': HookPoint(), 'blocks.8.attn.hook_v': HookPoint(), 'blocks.8.attn.hook_z': HookPoint(), 'blocks.8.attn.hook_attn_scores': HookPoint(), 'blocks.8.attn.hook_pattern': HookPoint(), 'blocks.8.attn.hook_result': HookPoint(), 'blocks.8.mlp.hook_pre': HookPoint(), 'blocks.8.mlp.hook_post': HookPoint(), 'blocks.8.hook_attn_in': HookPoint(), 'blocks.8.hook_q_input': HookPoint(), 'blocks.8.hook_k_input': HookPoint(), 'blocks.8.hook_v_input': HookPoint(), 'blocks.8.hook_mlp_in': HookPoint(), 'blocks.8.hook_attn_out': HookPoint(), 'blocks.8.hook_mlp_out': HookPoint(), 'blocks.8.hook_resid_pre': HookPoint(), 'blocks.8.hook_resid_mid': HookPoint(), 'blocks.8.hook_resid_post': HookPoint(), 'blocks.9.ln1.hook_scale': HookPoint(), 'blocks.9.ln1.hook_normalized': HookPoint(), 'blocks.9.ln2.hook_scale': HookPoint(), 'blocks.9.ln2.hook_normalized': HookPoint(), 'blocks.9.attn.hook_k': HookPoint(), 'blocks.9.attn.hook_q': HookPoint(), 'blocks.9.attn.hook_v': HookPoint(), 'blocks.9.attn.hook_z': HookPoint(), 'blocks.9.attn.hook_attn_scores': HookPoint(), 'blocks.9.attn.hook_pattern': HookPoint(), 'blocks.9.attn.hook_result': HookPoint(), 'blocks.9.mlp.hook_pre': HookPoint(), 'blocks.9.mlp.hook_post': HookPoint(), 'blocks.9.hook_attn_in': HookPoint(), 'blocks.9.hook_q_input': HookPoint(), 'blocks.9.hook_k_input': HookPoint(), 'blocks.9.hook_v_input': HookPoint(), 'blocks.9.hook_mlp_in': HookPoint(), 'blocks.9.hook_attn_out': HookPoint(), 'blocks.9.hook_mlp_out': HookPoint(), 'blocks.9.hook_resid_pre': HookPoint(), 'blocks.9.hook_resid_mid': HookPoint(), 'blocks.9.hook_resid_post': HookPoint(), 'blocks.10.ln1.hook_scale': HookPoint(), 'blocks.10.ln1.hook_normalized': HookPoint(), 'blocks.10.ln2.hook_scale': HookPoint(), 'blocks.10.ln2.hook_normalized': HookPoint(), 'blocks.10.attn.hook_k': HookPoint(), 'blocks.10.attn.hook_q': HookPoint(), 'blocks.10.attn.hook_v': HookPoint(), 'blocks.10.attn.hook_z': HookPoint(), 'blocks.10.attn.hook_attn_scores': HookPoint(), 'blocks.10.attn.hook_pattern': HookPoint(), 'blocks.10.attn.hook_result': HookPoint(), 'blocks.10.mlp.hook_pre': HookPoint(), 'blocks.10.mlp.hook_post': HookPoint(), 'blocks.10.hook_attn_in': HookPoint(), 'blocks.10.hook_q_input': HookPoint(), 'blocks.10.hook_k_input': HookPoint(), 'blocks.10.hook_v_input': HookPoint(), 'blocks.10.hook_mlp_in': HookPoint(), 'blocks.10.hook_attn_out': HookPoint(), 'blocks.10.hook_mlp_out': HookPoint(), 'blocks.10.hook_resid_pre': HookPoint(), 'blocks.10.hook_resid_mid': HookPoint(), 'blocks.10.hook_resid_post': HookPoint(), 'blocks.11.ln1.hook_scale': HookPoint(), 'blocks.11.ln1.hook_normalized': HookPoint(), 'blocks.11.ln2.hook_scale': HookPoint(), 'blocks.11.ln2.hook_normalized': HookPoint(), 'blocks.11.attn.hook_k': HookPoint(), 'blocks.11.attn.hook_q': HookPoint(), 'blocks.11.attn.hook_v': HookPoint(), 'blocks.11.attn.hook_z': HookPoint(), 'blocks.11.attn.hook_attn_scores': HookPoint(), 'blocks.11.attn.hook_pattern': HookPoint(), 'blocks.11.attn.hook_result': HookPoint(), 'blocks.11.mlp.hook_pre': HookPoint(), 'blocks.11.mlp.hook_post': HookPoint(), 'blocks.11.hook_attn_in': HookPoint(), 'blocks.11.hook_q_input': HookPoint(), 'blocks.11.hook_k_input': HookPoint(), 'blocks.11.hook_v_input': HookPoint(), 'blocks.11.hook_mlp_in': HookPoint(), 'blocks.11.hook_attn_out': HookPoint(), 'blocks.11.hook_mlp_out': HookPoint(), 'blocks.11.hook_resid_pre': HookPoint(), 'blocks.11.hook_resid_mid': HookPoint(), 'blocks.11.hook_resid_post': HookPoint(), 'ln_final.hook_scale': HookPoint(), 'ln_final.hook_normalized': HookPoint()}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_head(attention_pattern):\n",
        "  expected_attention = attention_pattern[1:,1:][t.from_numpy(masks[sequence_index]).bool()] # slice attention to ignore |endoftext| and then apply mask\n",
        "  return t.mean(expected_attention)\n",
        "\n",
        "#perform mean ablation on positional embedding\n",
        "def positional_embedding_ablation_hook(\n",
        "    pos_embed, # : Float[t.Tensor, \"n_ctx d_model\"],\n",
        "    hook: HookPoint,\n",
        "):\n",
        "  pos_embed = pos_embed.mean(0)\n",
        "\n",
        "\n",
        "\n",
        "model.add_caching_hooks('blocks.1.attn.hook_pattern')\n",
        "attention_pattern = model.run_with_hooks(input_tokens, fwd_hooks=[('hook_pos_embed', positional_embedding_ablation_hook)])\n",
        "print(cache)\n",
        "ablated_score = eval_head(attention_pattern)\n",
        "print(ablated_score)"
      ],
      "metadata": {
        "id": "mOfOpkjC21An",
        "outputId": "9464d425-bffe-4a31-f010-1e29f7459470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ActivationCache with keys ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "The shape of the mask [12, 12] at index 0 does not match the shape of the indexed tensor [0, 12, 50257] at index 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3289199651.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mattention_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfwd_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hook_pos_embed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositional_embedding_ablation_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mablated_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mablated_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3289199651.py\u001b[0m in \u001b[0;36meval_head\u001b[0;34m(attention_pattern)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mexpected_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_pattern\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# slice attention to ignore |endoftext| and then apply mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_attention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#perform mean ablation on positional embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [12, 12] at index 0 does not match the shape of the indexed tensor [0, 12, 50257] at index 0"
          ]
        }
      ]
    }
  ]
}